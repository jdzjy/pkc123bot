# --- START OF FILE bot115.py ---

import requests
import os
import logging
from bs4 import BeautifulSoup
import time
import sqlite3
import json
import re
import schedule
from datetime import datetime
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from urllib.parse import urlsplit, parse_qs, urlparse, unquote
from p115client import P115Client
from p115client.exception import P115OSError, P115AuthenticationError

# === å°è¯•å¯¼å…¥ Selenium ===
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from selenium.common.exceptions import TimeoutException, NoSuchElementException
    SELENIUM_INSTALLED = True
except ImportError:
    SELENIUM_INSTALLED = False

try:
    from p115client import check_response
except ImportError:
    from p115client.tool import check_response
try:
    from p115client.tool import normalize_attr as normalize_attr_simple
except ImportError:
    # å…¼å®¹æ—§ç‰ˆæœ¬æˆ–ç›´æ¥å®šä¹‰ä¸€ä¸ªç®€å•çš„
    def normalize_attr_simple(attr):
        return attr

from dotenv import load_dotenv


class TransferResult:
    """
    æ™ºèƒ½ç»“æœç±»
    success: ç”¨äº if åˆ¤æ–­ï¼ˆå…¼å®¹æ—§é€»è¾‘ï¼‰
    message: ç”¨äºæ˜¾ç¤ºç»™ç”¨æˆ·çš„æ–‡å­—
    skipped: ã€æ–°ã€‘ç”¨äºä»£ç é€»è¾‘åˆ¤æ–­æ˜¯å¦è·³è¿‡
    """
    def __init__(self, success: bool, message: str = "", skipped: bool = False):
        self.success = success
        self.message = message
        self.skipped = skipped  

    def __bool__(self):
        return self.success

    def __str__(self):
        return self.message

logger = logging.getLogger(__name__)
banbenhao = "1.3.17" # ç‰ˆæœ¬å·ï¼šé›†æˆ ed2k ç¦»çº¿ä¸‹è½½ä¸ Telegraph æ·±åº¦è§£æ

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv(dotenv_path="db/user.env", override=True)
load_dotenv(dotenv_path="sys.env", override=True)

# é…ç½®éƒ¨åˆ†
def get_int_env(env_name, default_value=0):
    try:
        value = os.getenv(env_name, str(default_value))
        return int(value) if value else default_value
    except (ValueError, TypeError):
        logger.warning(f"ç¯å¢ƒå˜é‡ {env_name} å€¼ä¸æ˜¯æœ‰æ•ˆçš„æ•´æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {default_value}")
        return default_value

CHANNEL_URL = os.getenv("ENV_115_TG_CHANNEL", "")
COOKIES = os.getenv("ENV_115_COOKIES", "")
UPLOAD_TARGET_PID = get_int_env("ENV_UPLOAD_PID", 0)
UPLOAD_TRANSFER_PID = get_int_env("ENV_115_UPLOAD_PID", 0)

TG_BOT_TOKEN = os.getenv("ENV_TG_BOT_TOKEN", "")
TG_ADMIN_USER_ID = get_int_env("ENV_TG_ADMIN_USER_ID", 0)

# æ¸…ç†ä»»åŠ¡é…ç½®å‚æ•°
CLEAN_TARGET_PID = os.getenv("ENV_115_CLEAN_PID", "0,0")
TRASH_PASSWORD = get_int_env("ENV_115_TRASH_PASSWORD", 0)

# === HDHive é…ç½® ===
HDHIVE_USERNAME = os.getenv("ENV_HDHIVE_USERNAME", "")
HDHIVE_PASSWORD = os.getenv("ENV_HDHIVE_PASSWORD", "")
HDHIVE_MAX_POINTS = get_int_env("ENV_HDHIVE_MAX_POINTS", 2) # å•ä¸ªèµ„æºå…è®¸çš„æœ€å¤§ç§¯åˆ†æ¶ˆè€—
HDHIVE_SESSION_FILE = os.path.join("db", "hdhive_session.json")

# å…¨å±€å˜é‡è®°å½•æœ¬æ¬¡è¿è¡Œæ¶ˆè€—çš„ç§¯åˆ†
hdhive_points_consumed_this_run = 0

# æ•°æ®åº“æ–‡ä»¶è·¯å¾„
DB_DIR = "db"
if not os.path.exists(DB_DIR):
    os.makedirs(DB_DIR)
DATABASE_FILE = os.path.join(DB_DIR, "TG_monitor-115.db")
COOKIES_FILE = os.path.join(DB_DIR, "115_cookies.txt") 
CHECK_INTERVAL = get_int_env("ENV_CHECK_INTERVAL", 5)
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.5 Safari/605.1.15"
]
RETRY_TIMES = 3
TIMEOUT = 15

# å…¨å±€115å®¢æˆ·ç«¯
client_115 = None

# ç»Ÿè®¡
stats = {
    "total_files": 0
}
# === HDHive åˆå§‹åŒ–æ ‡è®° ===
HDHIVE_INIT_DONE = False

# === ç±»å®šä¹‰ ===

class TelegramNotifier:
    def __init__(self, bot_token, user_id):
        self.bot_token = bot_token
        self.user_id = user_id
        self.base_url = f"https://api.telegram.org/bot{self.bot_token}/" if self.bot_token else None

    def send_message(self, message):
        """å‘æŒ‡å®šç”¨æˆ·å‘é€æ¶ˆæ¯"""
        max_retries = 3
        retry_delay = 5

        if not self.bot_token:
            logger.error("æœªè®¾ç½®bot_tokenï¼Œè·³è¿‡å‘é€æ¶ˆæ¯")
            return False
        if not message:
            return False
            
        success_count = 0
        params = {
            "chat_id": self.user_id,
            "text": message
        }

        for attempt in range(max_retries):
            try:
                response = requests.get(
                    f"{self.base_url}sendMessage",
                    params=params,
                    timeout=15
                )
                response.raise_for_status()
                result = response.json()
                if result.get("ok", False):
                    logger.info(f"æ¶ˆæ¯å·²å‘é€")
                    success_count += 1
                    break
                else:
                    logger.error(f"å‘é€å¤±è´¥: {result}")
            except requests.exceptions.RequestException as e:
                logger.error(f"å‘é€å¼‚å¸¸ï¼Œé‡è¯•ä¸­: {str(e)}")

            if attempt < max_retries - 1:
                time.sleep(retry_delay)

        return success_count > 0

class HDHiveManager:
    """HDHive ç®¡ç†ç±»"""
    def __init__(self, notifier=None):
        self.base_url = "https://hdhive.com"
        self.notifier = notifier
        self.cookies = {}
        self.tokens = {} 
        self.load_session()

    def load_session(self):
        """åŠ è½½æœ¬åœ°ä¿å­˜çš„ä¼šè¯ä¿¡æ¯"""
        if os.path.exists(HDHIVE_SESSION_FILE):
            try:
                with open(HDHIVE_SESSION_FILE, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.cookies = data.get('cookies', {})
                    self.tokens = data.get('tokens', {})
                    for c in self.cookies.get('list', []):
                         if 'expiry' in c: c['expiry'] = int(c['expiry'])
            except Exception as e:
                logger.warning(f"åŠ è½½ HDHive ä¼šè¯å¤±è´¥: {e}")

    def save_session(self, driver_cookies):
        """ä¿å­˜ä¼šè¯ä¿¡æ¯"""
        try:
            tokens = {}
            cookie_dict = {}
            for c in driver_cookies:
                name = c.get('name')
                value = c.get('value')
                cookie_dict[name] = value
                if name == 'token':
                    tokens['token'] = value
                elif name == 'csrf_access_token':
                    tokens['csrf'] = value
            
            self.cookies = {'list': driver_cookies, 'dict': cookie_dict}
            self.tokens = tokens
            
            with open(HDHIVE_SESSION_FILE, 'w', encoding='utf-8') as f:
                json.dump({'cookies': self.cookies, 'tokens': self.tokens}, f)
            logger.info("HDHive ä¼šè¯å·²ä¿å­˜")
        except Exception as e:
            logger.error(f"ä¿å­˜ HDHive ä¼šè¯å¤±è´¥: {e}")

    def _create_driver(self):
        """åˆ›å»ºé…ç½®å¥½çš„ Chrome Driver"""
        if not SELENIUM_INSTALLED:
            raise ImportError("Selenium æœªå®‰è£…")
        
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--log-level=3') 
        chrome_options.add_argument(f'user-agent={USER_AGENTS[0]}')
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        return driver

    def login(self, driver):
        """åœ¨å·²æœ‰ driver ä¸Šæ‰§è¡Œç™»å½•åŠ¨ä½œ"""
        if not HDHIVE_USERNAME or not HDHIVE_PASSWORD:
            logger.warning("[HDHive] æœªé…ç½® HDHive ç”¨æˆ·åæˆ–å¯†ç ï¼Œè·³è¿‡ç™»å½•")
            return False

        logger.info(f"[HDHive] æ­£åœ¨å°è¯•ç™»å½•... ç”¨æˆ·: {HDHIVE_USERNAME}")
        try:
            driver.get(f"{self.base_url}/login")
            time.sleep(3)

            cookies = driver.get_cookies()
            if "token" in [c['name'] for c in cookies]:
                logger.info("[HDHive] Cookie æœ‰æ•ˆï¼Œæ— éœ€é‡æ–°ç™»å½•")
                self.save_session(cookies)
                return True

            wait = WebDriverWait(driver, 10)
            username_input = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='text'], input[name='username']")))
            password_input = driver.find_element(By.CSS_SELECTOR, "input[type='password'], input[name='password']")
            
            username_input.clear()
            username_input.send_keys(HDHIVE_USERNAME)
            password_input.clear()
            password_input.send_keys(HDHIVE_PASSWORD)
            
            submit_btn = driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
            driver.execute_script("arguments[0].click();", submit_btn)
            
            logger.info("[HDHive] æäº¤ç™»å½•ï¼Œç­‰å¾…è·³è½¬...")
            time.sleep(5)
            cookies = driver.get_cookies()
            if "token" in [c['name'] for c in cookies] or driver.current_url == self.base_url:
                logger.info("[HDHive] ç™»å½•æˆåŠŸ")
                self.save_session(cookies)
                return True
            else:
                logger.error(f"[HDHive] ç™»å½•å¤±è´¥ï¼Œå½“å‰é¡µé¢: {driver.current_url}")
                raise Exception("ç™»å½•è¡¨å•æäº¤åæœªæ£€æµ‹åˆ°æœ‰æ•ˆ Session")

        except Exception as e:
            msg = f"HDHive ç™»å½•å¼‚å¸¸: {str(e)}"
            logger.error(msg)
            if self.notifier: self.notifier.send_message(f"âš ï¸ {msg}")
            return False

    def force_login(self):
        """å¼ºåˆ¶å¯åŠ¨ä¸€ä¸ªæ–°çš„æµè§ˆå™¨å®ä¾‹è¿›è¡Œç™»å½•"""
        if not SELENIUM_INSTALLED: return False
        
        driver = None
        try:
            logger.info("[HDHive] å¯åŠ¨ç‹¬ç«‹æµè§ˆå™¨å®ä¾‹è¿›è¡Œç™»å½•ä¿®å¤...")
            driver = self._create_driver()
            # å…ˆæ³¨å…¥æ—§ Cookie å°è¯•
            driver.get(self.base_url)
            if self.cookies.get('list'):
                for c in self.cookies['list']:
                    try:
                        clean = {k: v for k, v in c.items() if k in ['name', 'value', 'path', 'domain', 'secure', 'expiry']}
                        if 'domain' not in clean: clean['domain'] = '.hdhive.com'
                        driver.add_cookie(clean)
                    except: pass
            
            return self.login(driver)
        except Exception as e:
            logger.error(f"[HDHive] å¼ºåˆ¶ç™»å½•æµç¨‹å¼‚å¸¸: {e}")
            return False
        finally:
            if driver: driver.quit()

    def check_in(self, report=False):
        """
        æ¯æ—¥ç­¾åˆ° / ä¿æ´»æ£€æµ‹
        :param report: æ˜¯å¦å¼ºåˆ¶æ±‡æŠ¥ç»“æœï¼ˆç”¨äºæ¯æ—¥å®šæ—¶ä»»åŠ¡ï¼‰
        """
        # å¿«é€Ÿæ£€æŸ¥é…ç½®
        if not (HDHIVE_USERNAME and HDHIVE_PASSWORD) and not self.cookies:
            return

        if not HDHIVE_USERNAME or not HDHIVE_PASSWORD:
            return

        # 1. å¦‚æœå®Œå…¨æ²¡æœ‰ Tokenï¼Œå…ˆç™»å½•
        if not self.tokens.get('token'):
            logger.info("[HDHive] æœ¬åœ°æ—  Tokenï¼Œå°è¯•ç«‹å³ç™»å½•...")
            if self.force_login():
                self.load_session()
            else:
                return

        # 2. å‡†å¤‡è¯·æ±‚
        url = f"{self.base_url}/api/customer/user/checkin"
        headers = {
            "authority": "hdhive.com",
            "method": "POST",
            "path": "/api/customer/user/checkin",
            "scheme": "https",
            "accept": "application/json, text/plain, */*",
            "authorization": f"Bearer {self.tokens.get('token')}",
            "content-type": "application/json",
            "cookie": f"token={self.tokens.get('token')}; csrf_access_token={self.tokens.get('csrf')}",
            "origin": self.base_url,
            "referer": f"{self.base_url}/",
            "user-agent": USER_AGENTS[0],
            "x-csrf-token": self.tokens.get('csrf')
        }

        # 3. æ‰§è¡Œè¯·æ±‚ï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰
        try:
            resp = requests.post(url, headers=headers, timeout=10)
            
            # === å¤„ç† Token å¤±æ•ˆ (å…³é”®ä¿æ´»é€»è¾‘) ===
            if resp.status_code in [401, 403]:
                logger.warning(f"[HDHive] ä»¤ç‰Œå·²å¤±æ•ˆ (Status {resp.status_code})ï¼Œæ­£åœ¨æ‰§è¡Œè‡ªåŠ¨ä¿æ´»/ç™»å½•...")
                
                if self.force_login():
                    self.load_session()
                    logger.info("[HDHive] ä¿æ´»æˆåŠŸï¼šä»¤ç‰Œå·²åˆ·æ–°")
                    
                    # é‡æ–°å°è¯•ç­¾åˆ°
                    headers["authorization"] = f"Bearer {self.tokens.get('token')}"
                    headers["cookie"] = f"token={self.tokens.get('token')}; csrf_access_token={self.tokens.get('csrf')}"
                    headers["x-csrf-token"] = self.tokens.get('csrf')
                    resp = requests.post(url, headers=headers, timeout=10)
                else:
                    logger.error("[HDHive] ä¿æ´»å¤±è´¥ï¼šæ— æ³•é‡æ–°ç™»å½•")
                    return
            # ========================================

            data = resp.json()
            if data.get('success'):
                msg = f"âœ… HDHive ç­¾åˆ°æˆåŠŸ: {data.get('message', 'OK')}"
                logger.info(msg)
                if self.notifier: self.notifier.send_message(msg)
            elif "ç­¾åˆ°è¿‡" in str(data.get('message', '')):
                msg = f"âœ… [HDHive] ä»Šæ—¥å·²ç­¾åˆ° (Sessionæœ‰æ•ˆ)"
                logger.info(msg)
                # ã€ä¿®æ”¹ç‚¹ã€‘å¦‚æœæ˜¯æ¯æ—¥å®šæ—¶æŠ¥å‘Šï¼Œå³ä½¿å·²ç­¾åˆ°ä¹Ÿè¦å‘é€šçŸ¥
                if report and self.notifier:
                    self.notifier.send_message(msg)
            else:
                msg = f"âš ï¸ [HDHive] ç­¾åˆ°çŠ¶æ€: {data.get('message')}"
                logger.info(msg)
                # ã€ä¿®æ”¹ç‚¹ã€‘å¼‚å¸¸çŠ¶æ€ä¹Ÿæ±‡æŠ¥
                if report and self.notifier:
                    self.notifier.send_message(msg)
                    
        except Exception as e:
            logger.error(f"[HDHive] ç­¾åˆ°/ä¿æ´»è¯·æ±‚å¼‚å¸¸: {e}")

    def parse_resource(self, url, message_url=None):
        """ä½¿ç”¨ Selenium è§£æèµ„æº (å¢å¼ºæå–é€»è¾‘)"""
        global hdhive_points_consumed_this_run
        
        if not SELENIUM_INSTALLED:
            logger.error("âŒ æœªå®‰è£… Seleniumï¼Œæ— æ³•è§£æ HDHive")
            return []

        # æ— é…ç½®/æ— ä¼šè¯æ—¶çš„å¿«é€Ÿæ‹¦æˆª
        if not (HDHIVE_USERNAME and HDHIVE_PASSWORD) and not self.cookies:
            logger.warning(f"âŒ [HDHive] æœªé…ç½®è´¦å·å¯†ç ä¸”æ— æœ‰æ•ˆä¼šè¯æ–‡ä»¶ï¼Œè·³è¿‡è§£æ: {url}")
            return []

        logger.info(f"ğŸ [HDHive-Debug] å¯åŠ¨è§£æ: {url}")
        driver = None
        found_links = []

        try:
            logger.info("  [HDHive-Debug] æ­£åœ¨å¯åŠ¨ Chrome Driver...")
            driver = self._create_driver()
            
            # æ³¨å…¥ Cookie
            driver.get(self.base_url)
            if self.cookies.get('list'):
                for c in self.cookies['list']:
                    try: 
                        clean_cookie = {k: v for k, v in c.items() if k in ['name', 'value', 'path', 'domain', 'secure', 'expiry']}
                        if 'domain' not in clean_cookie: clean_cookie['domain'] = '.hdhive.com'
                        driver.add_cookie(clean_cookie)
                    except: pass
            
            driver.get(url)
            logger.info(f"  [HDHive-Debug] é¡µé¢åŠ è½½å®Œæˆ. Title: '{driver.title}'")

            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            page_src = driver.page_source
            if "è¯·å…ˆç™»å½•" in page_src or "login" in driver.current_url:
                logger.info("  [HDHive-Debug] æ£€æµ‹åˆ°æœªç™»å½•çŠ¶æ€ï¼Œå°è¯•æ‰§è¡Œç™»å½•æµç¨‹...")
                if self.login(driver):
                    logger.info("  [HDHive-Debug] ç™»å½•æˆåŠŸï¼Œåˆ·æ–°é¡µé¢...")
                    driver.get(url) 
                else:
                    return []

            # === å°è¯•è§£é” ===
            cost = 0
            try:
                logger.info("  [HDHive-Debug] æ­£åœ¨å¯»æ‰¾è§£é”/æ”¯ä»˜æŒ‰é’®...")
                wait = WebDriverWait(driver, 8)
                
                xpath = "//button[contains(., 'ç¡®å®šè§£é”') or contains(., 'è§£é”') or contains(., 'Unlock') or contains(., 'æ”¯ä»˜')]"
                button = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))
                
                if button:
                    logger.info(f"  [HDHive-Debug] æ‰¾åˆ°æŒ‰é’®: '{button.text.strip()}'")
                    
                    # === ç§¯åˆ†æ£€æµ‹ logic (æ­£æ–‡ä¼˜å…ˆ) ===
                    current_page_text = driver.find_element(By.TAG_NAME, "body").text
                    points_match = re.search(r'éœ€è¦ä½¿ç”¨\s*(\d+)\s*ç§¯åˆ†', current_page_text)
                    
                    if points_match:
                        cost = int(points_match.group(1))
                        logger.info(f"  [HDHive-Debug] ä»é¡µé¢æç¤ºä¸­æ£€æµ‹åˆ°è´¹ç”¨: {cost} ç§¯åˆ†")
                    else:
                        btn_match = re.search(r'(\d+)\s*ç§¯åˆ†', button.text)
                        if btn_match:
                            cost = int(btn_match.group(1))
                            logger.info(f"  [HDHive-Debug] ä»æŒ‰é’®æ–‡æœ¬æ£€æµ‹åˆ°è´¹ç”¨: {cost} ç§¯åˆ†")
                        else:
                            logger.info("  [HDHive-Debug] æœªæ£€æµ‹åˆ°æ˜ç¡®çš„ç§¯åˆ†æ‰£é™¤æç¤ºï¼Œå¯èƒ½ä¸ºå…è´¹æˆ–å·²è§£é”")

                    # === å•æ¬¡æ¶ˆè€—é˜ˆå€¼æ£€æŸ¥ ===
                    source_info = f"\næ¶ˆæ¯å†…å®¹: {message_url}" if message_url else ""
                    source_info += f"\nğŸ”— æ¥æº: {url}"

                    if cost > 0 and cost > HDHIVE_MAX_POINTS:
                         msg = f"ğŸ›‘ [HDHive] ç§¯åˆ†æ‹¦æˆª: æ­¤èµ„æºéœ€ {cost} ç§¯åˆ† (è¶…è¿‡å•æ¬¡ä¸Šé™ {HDHIVE_MAX_POINTS}){source_info}"
                         logger.warning(f"  [HDHive-Debug] ç§¯åˆ†æ‹¦æˆª: {cost} > {HDHIVE_MAX_POINTS}")
                         if self.notifier: self.notifier.send_message(msg)
                         return [] 
                    
                    logger.info("  [HDHive-Debug] æ‰§è¡Œç‚¹å‡»æ“ä½œ...")
                    driver.execute_script("arguments[0].click();", button)
                    
                    # æ£€æµ‹ç‚¹å‡»åé¦ˆ
                    time.sleep(1.5)
                    if "ç§¯åˆ†ä¸è¶³" in driver.page_source:
                        msg = f"âŒ [HDHive] è´¦æˆ·ç§¯åˆ†ä¸è¶³ï¼Œæ— æ³•è§£é”èµ„æº{source_info}"
                        logger.error(f"  [HDHive-Debug] è´¦æˆ·ç§¯åˆ†ä¸è¶³")
                        if self.notifier: self.notifier.send_message(msg)
                        return []
                        
                    # ç­‰å¾…è·³è½¬
                    logger.info("  [HDHive-Debug] ç‚¹å‡»å®Œæˆï¼Œç­‰å¾…é¡µé¢æ›´æ–°...")
                    start_time = time.time()
                    while time.time() - start_time < 15:
                        curr = driver.current_url
                        src = driver.page_source
                        if any(d in curr for d in ['115.com', '115cdn.com', 'anxia.com']): 
                            logger.info(f"  [HDHive-Debug] æ£€æµ‹åˆ°ç›®æ ‡è·³è½¬: {curr}")
                            break
                        if "password=" in src:
                            logger.info("  [HDHive-Debug] æ£€æµ‹åˆ°é¡µé¢å·²åˆ·æ–°å‡ºåŒ…å«å¯†ç çš„é“¾æ¥")
                            break
                        time.sleep(1)
                    
                    # åªæœ‰ç¡®å®ç‚¹å‡»å¹¶æ¶ˆè€—äº†ç§¯åˆ†æ‰è®¡è´¹
                    if cost > 0:
                        hdhive_points_consumed_this_run += cost

            except TimeoutException:
                 logger.info("  [HDHive-Debug] æœªè§¦å‘ç‚¹å‡»æµç¨‹(æœªæ‰¾åˆ°æŒ‰é’®æˆ–å·²è§£é”)ï¼Œç»§ç»­å°è¯•æå–é“¾æ¥")
                 # å¢åŠ é¢å¤–ç­‰å¾…ï¼Œé˜²æ­¢å…è´¹èµ„æºåŠ è½½æ…¢
                 time.sleep(2)
            except Exception as e:
                logger.error(f"  [HDHive-Debug] æŒ‰é’®äº¤äº’è¿‡ç¨‹å¼‚å¸¸: {e}")

            # === æå–é“¾æ¥ (å¢å¼ºç‰ˆ) ===
            final_url = driver.current_url
            page_source = driver.page_source
            
            # 1. æ£€æŸ¥å½“å‰ URL æ˜¯å¦ç›´æ¥å°±æ˜¯åˆ†äº«é“¾æ¥
            if any(d in final_url for d in ['115.com', '115cdn.com', 'anxia.com']):
                found_links.append(final_url)
            
            # 2. æ­£åˆ™åŒ¹é… (ä½¿ç”¨å®½æ³›åŒ¹é…)
            # åŒ¹é… http(s)://...115...com/s/... ç›´åˆ°é‡åˆ°ç©ºæ ¼ã€å¼•å·æˆ–å°–æ‹¬å·
            patterns = [
                r'https?://[^\s"\'<>]*115[^\s"\'<>]*\/s\/[^\s"\'<>]+'
            ]
            
            regex_count = 0
            for p in patterns:
                matches = re.findall(p, page_source)
                if matches:
                    regex_count += len(matches)
                    found_links.extend(matches)
            
            # 3. DOM æ‰«æ (æŸ¥æ‰¾æ‰€æœ‰ href å±æ€§åŒ…å« 115 åŸŸåçš„ a æ ‡ç­¾)
            try:
                logger.info("  [HDHive-Debug] æ­£åœ¨æ‰«æ DOM ä¸­çš„ <a> æ ‡ç­¾...")
                links = driver.find_elements(By.CSS_SELECTOR, "a[href*='115.com'], a[href*='115cdn.com'], a[href*='anxia.com']")
                for link in links:
                    href = link.get_attribute('href')
                    if href and '/s/' in href:
                        found_links.append(href)
                        logger.info(f"  [HDHive-Debug] DOM å‘ç°é“¾æ¥: {href}")
            except Exception as e:
                logger.warning(f"  [HDHive-Debug] DOM æ‰«æå¼‚å¸¸: {e}")

            logger.info(f"  [HDHive-Debug] æå–é“¾æ¥æ€»æ•° (å»é‡å‰): {len(found_links)}")
            
            # å»é‡å¹¶è¿‡æ»¤
            valid_links = []
            for link in set(found_links):
                # å†æ¬¡ç¡®è®¤æ˜¯æœ‰æ•ˆçš„åˆ†äº«æ ¼å¼
                if '/s/' in link:
                    valid_links.append(link)
            
            if not valid_links:
                logger.warning("  [HDHive-Debug] æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆé“¾æ¥")

            # === ç‹¬ç«‹å›å¤ç»“æœ ===
            source_info = f"\næ¶ˆæ¯å†…å®¹: {message_url}" if message_url else ""
            source_info += f"\nğŸ”— æ¥æº: {url}"

            if valid_links:
                if cost > 0:
                    reply_msg = f"ğŸ’° [HDHive] è§£ææˆåŠŸ (æ¶ˆè€— {cost} ç§¯åˆ†){source_info}"
                else:
                    reply_msg = f"âœ… [HDHive] è§£ææˆåŠŸ (å…è´¹/å·²è§£é”){source_info}"
                
                if self.notifier:
                    self.notifier.send_message(reply_msg)
            else:
                logger.warning(f"  [HDHive-Debug] è§£ææµç¨‹ç»“æŸï¼Œæœªæå–åˆ°æœ‰æ•ˆé“¾æ¥")

        except Exception as e:
            logger.error(f"  [HDHive-Debug] å…¨å±€è§£æå¼‚å¸¸: {e}", exc_info=True)
            if self.notifier:
                 self.notifier.send_message(f"âŒ [HDHive] ç³»ç»Ÿå¼‚å¸¸: {str(e)[:50]}")
        finally:
            if driver: driver.quit()
            
        return valid_links

# === æ–°å¢ï¼šHDHive ä¿æ´»ä»»åŠ¡ ===
def hdhive_keep_alive(report=False):
    """
    HDHive å®šæ—¶ä¿æ´»ä»»åŠ¡ (æ¯30åˆ†é’Ÿæ‰§è¡Œ)
    :param report: æ˜¯å¦å¼ºåˆ¶å‘é€é€šçŸ¥
    """
    try:
        if HDHIVE_USERNAME and HDHIVE_PASSWORD:
            action = "æ¯æ—¥ç­¾åˆ°æ±‡æŠ¥" if report else "ä¿æ´»æ£€æŸ¥"
            logger.info(f"ğŸ”„ æ‰§è¡Œ HDHive {action}...")
            notifier = TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID)
            manager = HDHiveManager(notifier)
            # ä¼ é€’ report å‚æ•°
            manager.check_in(report=report) 
    except Exception as e:
        logger.error(f"HDHive ä¿æ´»ä»»åŠ¡å¼‚å¸¸: {e}")

# === æ ¸å¿ƒå‡½æ•°ï¼š115 å®¢æˆ·ç«¯åˆå§‹åŒ– (è¿˜åŸç‰ˆï¼šä»…æ”¯æŒ Cookies) ===

def init_115_client(retry: bool = False) -> P115Client:
    """åˆå§‹åŒ–115å®¢æˆ·ç«¯"""
    import time
    import re
    
    cookies = None
    
    def clean_cookie_str(raw_str):
        if not raw_str: return ""
        valid_keys = ['UID', 'CID', 'SEID', 'KID', 'acw_tc']
        pairs = []
        for key in valid_keys:
            match = re.search(fr'(?:^|[\s;:]){key}=([^;\s]+)', raw_str, re.IGNORECASE)
            if match: 
                val = match.group(1)
                if "Set-Cookie" not in val:
                    pairs.append(f"{key}={val}")
        return "; ".join(pairs)

    if os.path.exists(COOKIES_FILE):
        try:
            with open(COOKIES_FILE, "r", encoding="utf-8") as f:
                raw_data = f.read().strip()
                cookies = clean_cookie_str(raw_data)
                
            if cookies:
                logger.info(f"å·²åŠ è½½æŒä¹…åŒ–cookies (æ¸…æ´—å): {cookies[:20]}...")
            else:
                logger.warning("æœ¬åœ°ç¼“å­˜æ–‡ä»¶å†…å®¹æ— æ•ˆï¼Œå·²å¿½ç•¥")
        except Exception as e:
            logger.warning(f"è¯»å–cookiesæ–‡ä»¶å¤±è´¥ï¼š{e}")
            if os.path.exists(COOKIES_FILE):
                os.remove(COOKIES_FILE)
    
    if cookies:
        while True:
            try:
                client = P115Client(cookies=cookies, app='web', check_for_relogin=True)
                user_info = client.user_my_info()
                sync_cookies_to_files(client_115) 
                
                if isinstance(user_info, dict) and not user_info.get('state'):
                     raise P115AuthenticationError("Cookieså·²å¤±æ•ˆï¼Œéœ€è¦é‡æ–°è·å–")

                logger.info(f"115å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨æŒä¹…åŒ–cookiesï¼‰ | ID: {client.user_id}")
                return client

            except Exception as e:
                err_str = str(e).lower()
                if "dictionary" in err_str or "sequence" in err_str or "expire" in err_str or "auth" in err_str or "errno 61" in err_str or "<html" in err_str:
                    logger.warning(f"æœ¬åœ°Cookiesä¸å¯ç”¨({e})ï¼Œåˆ é™¤æ—§æ–‡ä»¶")
                    if os.path.exists(COOKIES_FILE):
                        os.remove(COOKIES_FILE)
                    break 
                else:
                    logger.warning(f"cookiesæ£€æŸ¥å‘ç”ŸæœªçŸ¥å¼‚å¸¸ï¼Œ5ç§’åé‡è¯•ï¼š{e}")
                    time.sleep(5) 
                
    try:
        env_cookies = os.getenv("ENV_115_COOKIES", "").strip()
        if not env_cookies:
             raise ValueError("ç¯å¢ƒå˜é‡ ENV_115_COOKIES æœªé…ç½®")

        logger.info("å°è¯•ä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®çš„ Cookie åˆå§‹åŒ–...")
        clean_env_cookies = clean_cookie_str(env_cookies)
        
        client = P115Client(cookies=clean_env_cookies, app='web', check_for_relogin=True)
        client.user_my_info()

        try:
            with open(COOKIES_FILE, "w", encoding="utf-8") as f:
                f.write(clean_env_cookies)
        except Exception as write_e:
            logger.error(f"ä¿å­˜Cookieåˆ°æ–‡ä»¶å¤±è´¥: {write_e}")

        logger.info("115å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰")
        return client

    except Exception as e:
        if not retry:
            logger.error(f"ç¯å¢ƒå˜é‡åˆå§‹åŒ–å¤±è´¥ï¼š{e}ï¼Œå°è¯•é‡è¯•...")
            return init_115_client(retry=True)
        logger.error(f"115å®¢æˆ·ç«¯åˆå§‹åŒ–å½»åº•å¤±è´¥ï¼š{e}")
        raise

def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“"""
    conn = sqlite3.connect(DATABASE_FILE)
    conn.execute('''CREATE TABLE IF NOT EXISTS messages
                 (msg_id INTEGER PRIMARY KEY AUTOINCREMENT, id TEXT, date TEXT, message_url TEXT, target_url TEXT, 
                   transfer_status TEXT, transfer_time TEXT, transfer_result TEXT)''')
    conn.commit()
    conn.close()

def is_message_processed(message_id):
    """
    æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²å¤„ç† 
    (ä¿®æ”¹ä¸ºä½¿ç”¨ Telegram message_id å³ 'id' å­—æ®µåˆ¤æ–­ï¼Œè€Œé url)
    """
    conn = sqlite3.connect(DATABASE_FILE)
    try:
        # id å­—æ®µå­˜å‚¨çš„æ˜¯ telegram çš„ data-post å€¼ï¼Œå¦‚ "channelname/123"
        result = conn.execute("SELECT 1 FROM messages WHERE id = ?", (message_id,)).fetchone()
        return result is not None
    except Exception as e:
        logger.error(f"æŸ¥è¯¢æ•°æ®åº“å¤±è´¥: {e}")
        return False
    finally:
        conn.close()

def save_message(message_id, date, message_url, target_url,
                 status="å¾…è½¬å­˜", result="", transfer_time=None):
    """ä¿å­˜æ¶ˆæ¯åˆ°æ•°æ®åº“"""
    conn = sqlite3.connect(DATABASE_FILE)
    try:
        conn.execute("INSERT INTO messages (id, date, message_url, target_url, transfer_status, transfer_time, transfer_result) VALUES (?, ?, ?, ?, ?, ?, ?)",
                     (message_id, date, message_url, target_url,
                      status, transfer_time or datetime.now().isoformat(), result))
        conn.commit()
        logger.info(f"å·²è®°å½•: {message_id} | çŠ¶æ€: {status}")
    except sqlite3.IntegrityError:
        # å¦‚æœ id å·²å­˜åœ¨ï¼ˆè™½ç„¶ is_message_processed åº”è¯¥æ‹¦æˆªäº†ï¼Œä½†åŒé‡ä¿é™©ï¼‰
        conn.execute("UPDATE messages SET transfer_status=?, transfer_result=?, transfer_time=? WHERE id=?",
                     (status, result, transfer_time or datetime.now().isoformat(), message_id))
        conn.commit()
    finally:
        conn.close()

# === è¾…åŠ©å‡½æ•° ===

def validate_url(url):
    try:
        parsed = urlparse(url)
        if not parsed.scheme: url = f"https://{url}"
        parsed = urlparse(url)
        if parsed.scheme not in ('http', 'https') or not parsed.netloc: return None
        return url
    except: return None

# === æ›¿æ¢åŸæ¥çš„ add_offline_task å‡½æ•° ===
def add_offline_task(client, link, pid):
    """
    æ·»åŠ ç¦»çº¿ä»»åŠ¡ (ed2k/magnet)
    è¿”å› TransferResultï¼Œæºå¸¦"å·²å­˜åœ¨"çŠ¶æ€
    """
    try:
        payload = {
            'url': link, 'uid': client.user_id,
            'save_path_cid': pid, 'wp_path_id': pid, 'cid': pid
        }
        
        res = None
        if hasattr(client, 'offline_add_url'): res = client.offline_add_url(payload)
        elif hasattr(client, 'offline_add_urls'): res = client.offline_add_urls(payload)
        elif hasattr(client, 'download_add_url'):
             try: res = client.download_add_url(payload)
             except: res = client.download_add_url(url=link, cid=pid)

        if isinstance(res, list) and len(res) > 0: res = res[0]
            
        if isinstance(res, dict):
            if res.get('state'):
                logger.info(f"ed2kç¦»çº¿ä»»åŠ¡æ·»åŠ æˆåŠŸ: {link[:50]}...")
                return TransferResult(True, "âœ… ed2kç¦»çº¿ä»»åŠ¡æ·»åŠ æˆåŠŸ", skipped=False)
            
            # 2. å·²å­˜åœ¨ (skipped=True)
            err_msg = res.get('error_msg') or res.get('message') or str(res)
            if res.get('errNo') == 10008 or 'å­˜åœ¨' in str(err_msg) or 'exists' in str(err_msg):
                logger.info(f"ed2kç¦»çº¿ä»»åŠ¡å·²å­˜åœ¨ (è·³è¿‡): {link[:50]}...")
                return TransferResult(True, "ğŸ”„ ed2kç¦»çº¿ä»»åŠ¡å·²å­˜åœ¨ (è·³è¿‡)", skipped=True)
                
            logger.error(f"ed2kç¦»çº¿ä»»åŠ¡æ·»åŠ å¤±è´¥: {err_msg}")
            return TransferResult(False, f"âŒ å¤±è´¥: {err_msg}")
        else:
            return TransferResult(False, f"âŒ APIå¼‚å¸¸: {res}")

    except Exception as e:
        logger.error(f"ed2kç¦»çº¿ä»»åŠ¡æ·»åŠ å¼‚å¸¸: {e}")
        return TransferResult(False, f"âŒ å¼‚å¸¸: {str(e)}")

def parse_telegraph_page(url: str) -> list:
    """è§£æ Telegraph é¡µé¢ (æ”¯æŒ ed2k)"""
    try:
        logger.info(f"ğŸ“„ è§£æ Telegraph: {url}")
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        links = []
        # 1. æå–è¶…é“¾æ¥ (http å’Œ ed2k)
        for a in soup.find_all('a', href=True):
            href = a['href']
            if href.startswith('http'): 
                links.append(href)
            elif href.startswith('ed2k://'):
                links.append(href)
        
        # 2. æ‰«æçº¯æ–‡æœ¬ä¸­çš„ ed2k é“¾æ¥
        text_content = soup.get_text()
        ed2k_links = re.findall(r'ed2k://\|file\|.+?\|/', text_content, re.IGNORECASE)
        links.extend(ed2k_links)
        
        return list(set(links))
    except Exception as e:
        logger.error(f"Telegraph è§£æå¤±è´¥: {e}")
        return []

def parse_hdhive_with_selenium(url: str, message_url=None):
    """è§£æ HDHive é¡µé¢ (ä»£ç†ç»™ Manager å¤„ç†)"""
    notifier = TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID)
    manager = HDHiveManager(notifier)
    return manager.parse_resource(url, message_url)

def get_latest_messages():
    """è·å–æœ€æ–°æ¶ˆæ¯"""
    try:
        channel_urls = os.getenv("ENV_115_TG_CHANNEL", "").split('|')
        if not channel_urls or channel_urls == ['']:
            logger.warning("æœªé…ç½®ENV_115_TG_CHANNELç¯å¢ƒå˜é‡")
            return []
            
        all_new_messages = []
        
        for channel_idx, channel_url in enumerate(channel_urls):
            channel_url = channel_url.strip()
            if not channel_url:
                continue

            if channel_url.startswith('https://t.me/') and '/s/' not in channel_url:
                channel_name = channel_url.split('https://t.me/')[-1]
                channel_url = f'https://t.me/s/{channel_name}'

            logger.info(f"===== å¤„ç†é¢‘é“: {channel_url} =====")
            
            session = requests.Session()
            retry = Retry(total=RETRY_TIMES, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
            session.mount("https://", HTTPAdapter(max_retries=retry))
            headers = {"User-Agent": USER_AGENTS[int(time.time()) % len(USER_AGENTS)]}
            response = session.get(channel_url, headers=headers, timeout=TIMEOUT)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, 'html.parser')

            message_divs = soup.find_all('div', class_='tgme_widget_message')
            total = len(message_divs)
            logger.info(f"å…±è§£æåˆ°{total}æ¡æ¶ˆæ¯ï¼ˆæœ€æ–°çš„åœ¨æœ€åï¼‰")

            channel_new_count = 0 

            for i in range(total):
                msg_index = total - 1 - i
                msg = message_divs[msg_index]
                # data-post æ˜¯å”¯ä¸€ID (å¦‚ channelname/123)
                data_post = msg.get('data-post', '')
                message_id = data_post if data_post else f"æœªçŸ¥ID_{msg_index}"
                
                logger.info(f"æ£€æŸ¥ç¬¬{i + 1}æ–°æ¶ˆæ¯ï¼ˆID: {message_id}ï¼‰")

                # === å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ message_id è¿›è¡Œå»é‡ ===
                if is_message_processed(message_id):
                    logger.info(f"æ¶ˆæ¯ {message_id} å·²å¤„ç†ï¼Œè·³è¿‡")
                    continue
                # ========================================

                time_elem = msg.find('time')
                date_str = time_elem.get('datetime') if time_elem else datetime.now().isoformat()
                link_elem = msg.find('a', class_='tgme_widget_message_date')
                message_url = f"{link_elem.get('href').lstrip('/')}" if link_elem else ''
                
                text_elem = msg.find('div', class_='tgme_widget_message_text')
                message_text = ""
                if text_elem:
                    message_text = text_elem.get_text(strip=True).replace('\n', ' ')
                
                target_urls = extract_target_url(f"{msg}", message_url)
                
                if target_urls:
                    for url in target_urls:
                        # å¦‚æœ URL ä¸ºç©ºï¼ˆè¢«æ‹¦æˆªï¼‰ï¼Œä½†æˆ‘ä»¬éœ€è¦æ ‡è®°æ­¤æ¶ˆæ¯å·²å¤„ç†
                        # å¦åˆ™ä¸‹æ¬¡è¿˜ä¼šå°è¯•è§£æ
                        if not url:
                            save_message(message_id, date_str, message_url, "BLOCKED", "è¢«æ‹¦æˆª/æ— æ•ˆ")
                            continue

                        # æ­£å¸¸çš„æœ‰æ•ˆé“¾æ¥
                        all_new_messages.append((message_id, date_str, message_url, url, message_text))
                        channel_new_count += 1
                        logger.info(f"å‘ç°æ–°é“¾æ¥: {url}")
            
            logger.info(f"å‘ç°{channel_new_count}æ¡æ–°çš„115åˆ†äº«é“¾æ¥")
        
        all_new_messages.sort(key=lambda x: x[1])
        logger.info(f"===== æ‰€æœ‰é¢‘é“å…±å‘ç°{len(all_new_messages)}æ¡æ–°çš„115åˆ†äº«é“¾æ¥ =====")
        return all_new_messages

    except requests.exceptions.RequestException as e:
        logger.error(f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)[:100]}")
        return []

def extract_target_url(text, message_url=None):
    """æå–ç›®æ ‡ 115 é“¾æ¥ (åŒ…å« ed2k æ”¯æŒ)"""
    results = []
    
    # 1. ä¼˜å…ˆæå– ed2k é“¾æ¥
    ed2k_pattern = r'ed2k://\|file\|.+?\|/'
    ed2k_matches = re.findall(ed2k_pattern, text, re.IGNORECASE)
    if ed2k_matches:
        results.extend([m.strip() for m in ed2k_matches])

    # 2. æå– 115 åˆ†äº«é“¾æ¥
    p115_pattern = r'https?:\/\/(?:115|115cdn|anxia)\.com\/s\/\w+\?password\=\w+'
    matches = re.findall(p115_pattern, text, re.IGNORECASE | re.DOTALL)
    
    if matches:
        for match in matches:
            results.append(match.strip())
    
    intermediate_links = set()
    
    tg_matches = re.findall(r'https?://telegra\.ph/[^\s"\'<>]+', text, re.IGNORECASE)
    for m in tg_matches:
        v = validate_url(m)
        if v: intermediate_links.add(v)
        
    hd_matches = re.findall(r'https?://(?:www\.)?hdhive\.com/resource/[a-zA-Z0-9]+', text, re.IGNORECASE)
    for m in hd_matches:
        v = validate_url(m)
        if v: intermediate_links.add(v)
        
    for link in intermediate_links:
        parsed_links = []
        if 'telegra.ph' in link:
            parsed_links = parse_telegraph_page(link)
        elif 'hdhive.com' in link:
            # ä¼ é€’ message_urlï¼ŒHDHive ä¿æŒåŸæ ·ä»…æå– 115 åˆ†äº«
            parsed_links = parse_hdhive_with_selenium(link, message_url)
            # å¦‚æœè§£æç»“æœä¸ºç©ºï¼ˆä¾‹å¦‚è¢«æ‹¦æˆªï¼‰ï¼Œè¿”å› [None] ä»¥ä¾¿ä¸Šå±‚å¤„ç†è®°å½•
            if not parsed_links:
                results.append(None)

        if parsed_links:
            for pl in parsed_links:
                pl = pl.strip()
                # æ£€æŸ¥æ˜¯å¦ä¸º ed2k
                if pl.startswith('ed2k://'):
                    results.append(pl)
                else:
                    # æ£€æŸ¥æ˜¯å¦ä¸º 115 é“¾æ¥
                    pl_matches = re.findall(p115_pattern, pl, re.IGNORECASE)
                    if pl_matches:
                        for pm in pl_matches:
                            results.append(pm.strip())
                            logger.info(f"ğŸ”— ä»ä¸­é—´é¡µ {link} è§£æå‡º 115 é“¾æ¥: {pm.strip()}")

    # ç»“æœå»é‡
    valid_links = list(dict.fromkeys([r for r in results if r]))
    if None in results:
        valid_links.append(None)
        
    return valid_links

def parse_share_link(link):
    """ä»é“¾æ¥ä¸­è§£æ share_code å’Œ receive_code"""
    match = re.search(r'https?:\/\/(?:115|115cdn|anxia)\.com\/s\/(\w+)\?password\=(\w+)', link, re.IGNORECASE | re.DOTALL)
    if not match:
        return None
    return match.group(1), match.group(2)

# === æ›¿æ¢åŸæ¥çš„ transfer_shared_link å‡½æ•° ===
def transfer_shared_link(client: P115Client, share_url: str, target_pid: int):
    """
    è½¬å­˜ 115 åˆ†äº«é“¾æ¥ (åŸç”Ÿè¯·æ±‚ç‰ˆ + æ™ºèƒ½ç»“æœè¿”å›)
    """
    import json, requests, time, re
    
    if not share_url or not isinstance(share_url, str):
        return TransferResult(False, "æ— æ•ˆé“¾æ¥")
    share_url = share_url.strip()

    # ed2k åˆ†æµ -> ç›´æ¥è¿”å› add_offline_task çš„ç»“æœå¯¹è±¡
    if share_url.startswith('ed2k://'):
        return add_offline_task(client, share_url, target_pid)
    
    if share_url.startswith('magnet:?'):
        return TransferResult(False, "ç£åŠ›é“¾å·²å¿½ç•¥")

    def get_cookie_str(c):
        if isinstance(c, str): raw = c
        elif hasattr(c, 'get_dict'): raw = "; ".join([f"{k}={v}" for k, v in c.get_dict().items()])
        else: raw = str(c)
        
        valid_keys = ['UID', 'CID', 'SEID', 'KID', 'acw_tc']
        pairs = []
        for key in valid_keys:
            # === ä¼˜åŒ–ç‚¹ï¼šå…¼å®¹ key="value" æ ¼å¼ï¼Œå¹¶æ’é™¤åˆ†å·å’Œå¼•å· ===
            match = re.search(fr'(?:^|[\s;]){key}=(?:"?)([^;"\s]+)(?:"?)', raw, re.IGNORECASE)
            if match: 
                val = match.group(1)
                if "Set-Cookie" not in val and "HttpOnly" not in val:
                    pairs.append(f"{key}={val}")
        return "; ".join(pairs)

    try:
        clean_cookie = get_cookie_str(client.cookies)
        share_info = parse_share_link(share_url)
        if not share_info: return TransferResult(False, "é“¾æ¥æ ¼å¼é”™è¯¯")
        share_code, receive_code = share_info
        
        # è·å–æ–‡ä»¶åˆ—è¡¨ (é€»è¾‘ä¸å˜)
        file_ids = []
        offset = 0
        limit = 100 
        while True:
            url = "https://webapi.115.com/share/snap"
            params = {"share_code": share_code, "receive_code": receive_code, "offset": offset, "limit": limit}
            headers = {"User-Agent": USER_AGENTS[0], "Cookie": clean_cookie, "Referer": "https://115.com/", "Origin": "https://115.com"}
            try:
                r = requests.get(url, params=params, headers=headers, timeout=10)
                resp = r.json()
            except Exception as e:
                return TransferResult(False, f"ç½‘ç»œå¼‚å¸¸: {e}")

            if not resp.get('state'):
                return TransferResult(False, f"è·å–åˆ—è¡¨å¤±è´¥: {resp.get('error', 'æœªçŸ¥')}")
                
            data = resp.get('data', {})
            count = data.get('count', 0)
            file_list = data.get('list', [])
            if not file_list: break
            for item in file_list:
                fid = item.get('fid') or item.get('cid')
                if fid: file_ids.append(fid)
            if len(file_ids) >= count: break
            offset += len(file_list)
            time.sleep(0.3)

        if not file_ids:
            return TransferResult(False, "æ— æœ‰æ•ˆæ–‡ä»¶")

        # æ‰§è¡Œè½¬å­˜
        BATCH_SIZE = 50
        total_success = 0
        url_rec = "https://webapi.115.com/share/receive"
        headers_rec = {
            "User-Agent": USER_AGENTS[0], "Cookie": clean_cookie, 
            "Content-Type": "application/x-www-form-urlencoded", "Referer": "https://115.com/", "Origin": "https://115.com"
        }

        for i in range(0, len(file_ids), BATCH_SIZE):
            batch = file_ids[i : i + BATCH_SIZE]
            file_id_str = ",".join(map(str, batch))
            payload = {"user_id": client.user_id, "share_code": share_code, "receive_code": receive_code, "file_id": file_id_str, "cid": str(target_pid)}
            try:
                r = requests.post(url_rec, data=payload, headers=headers_rec, timeout=15)
                res_json = r.json()
                if res_json.get('state') or "æ— éœ€é‡å¤" in res_json.get('error', ''):
                    total_success += len(batch)
            except: pass
            time.sleep(1)

        if total_success == len(file_ids):
            return TransferResult(True, f"âœ… 115ç½‘ç›˜è½¬å­˜æˆåŠŸ")
        elif total_success > 0:
            return TransferResult(True, f"âš ï¸ 115ç½‘ç›˜éƒ¨åˆ†è½¬å­˜ ({total_success}/{len(file_ids)})")
        else:
            return TransferResult(False, "âŒ 115ç½‘ç›˜è½¬å­˜å…¨éƒ¨å¤±è´¥")

    except Exception as e:
        logger.error(f"115ç½‘ç›˜è½¬å­˜å¼‚å¸¸: {e}")
        return TransferResult(False, f"âŒ å¼‚å¸¸: {str(e)}")

def print_progress(msg, indent=0):
    """å¸¦ç¼©è¿›çš„è¿›åº¦è¾“å‡º"""
    prefix = "  " * indent
    logger.info(f"{prefix}[{time.strftime('%H:%M:%S')}] {msg}")

def transfer_and_clean():
    """é€’å½’è½¬ç§»æ–‡ä»¶å¹¶æ¸…ç†ç©ºç›®å½•"""
    global stats
    if not client_115:
        init_115_client()
    client = client_115

    def recursive_transfer(current_pid: int, depth=0):
        try:
            dir_info = client.fs_files(cid=current_pid, limit=1)
            dir_name = f"ç›®å½•#{current_pid}"
            if dir_info.get("path"):
                 dir_name = dir_info["path"][-1]["name"]
        except:
            dir_name = f"ç›®å½•#{current_pid}"
        
        print_progress(f"æ‰«æç›®å½•: {dir_name} ({current_pid})", depth)

        items = []
        offset = 0
        limit = 1000
        while True:
            try:
                resp = client.fs_files(cid=current_pid, limit=limit, offset=offset)
                check_response(resp)
                data = resp.get("data", [])
                if isinstance(data, dict):
                    page_items = data.get("list", [])
                else:
                    page_items = data
                items.extend(page_items)
                if len(page_items) < limit: break
                offset += limit
                print_progress(f"  è¯»å–åˆ†é¡µ: {offset / limit + 1}", depth + 1)
            except Exception as e:
                print_progress(f"âš ï¸ è·å–ç›®å½•å†…å®¹å¤±è´¥: {str(e)}", depth + 1)
                break

        print_progress(f"å‘ç° {len(items)} ä¸ªé¡¹ç›®", depth + 1)

        files = [item for item in items if not normalize_attr_simple(item)["is_dir"]]
        dirs = [item for item in items if normalize_attr_simple(item)["is_dir"]]

        for i, file in enumerate(files, 1):
            normalized = normalize_attr_simple(file)
            file_name = normalized.get("name", f"æ–‡ä»¶#{normalized['id']}")
            progress = f"{i}/{len(files)}"
            try:
                move_resp = client.fs_move(normalized["id"], UPLOAD_TARGET_PID)
                if not move_resp.get('state'):
                     raise P115OSError(move_resp.get('error'))
                print_progress(f"âœ… ç§»åŠ¨æ–‡ä»¶: {file_name} ({progress})", depth + 1)
                stats["total_files"] += 1
            except Exception as e:
                print_progress(f"âŒ ç§»åŠ¨å¤±è´¥: {file_name} ({progress}) - {str(e)}", depth + 1)
            time.sleep(0.2)

        for directory in dirs:
            dir_id = normalize_attr_simple(directory)["id"]
            if dir_id == UPLOAD_TARGET_PID: continue
            recursive_transfer(dir_id, depth + 1)

        try:
            after_resp = client.fs_files(cid=current_pid, limit=10)
            check_response(after_resp)
            data_after = after_resp.get("data", [])
            items_after = data_after.get("list", []) if isinstance(data_after, dict) else data_after

            if (not items_after
                    and current_pid != UPLOAD_TARGET_PID
                    and current_pid != UPLOAD_TRANSFER_PID):
                del_resp = client.fs_delete(current_pid)
                check_response(del_resp)
                print_progress(f"ğŸ—‘ï¸ åˆ é™¤ç©ºç›®å½•: {dir_name} ({current_pid})", depth)
                time.sleep(1)
        except Exception as e:
            print_progress(f"âš ï¸ åˆ é™¤ç›®å½•å¤±è´¥: {dir_name} ({current_pid}) - {str(e)}", depth)

    if UPLOAD_TRANSFER_PID == 0:
        raise ValueError("è½¬ç§»ç›®å½•IDä¸èƒ½ä¸º0")

    logger.info("===== å¼€å§‹æ–‡ä»¶è½¬ç§»å’Œç›®å½•æ¸…ç† =====")
    logger.info(f"æºç›®å½•: {UPLOAD_TRANSFER_PID}")
    logger.info(f"ç›®æ ‡ç›®å½•: {UPLOAD_TARGET_PID}")
    try:
        recursive_transfer(UPLOAD_TRANSFER_PID)
    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    finally:
        logger.info("===== æ“ä½œå®Œæˆ =====")
        logger.info(f"ç¨‹åºè‡ªå¯åŠ¨åå…±è½¬å­˜æ–‡ä»¶æ•°: {stats['total_files']}")

def clean_task():
    """æ‰§è¡Œæ¸…ç†ä»»åŠ¡"""
    target_pids = [pid.strip() for pid in CLEAN_TARGET_PID.split(",") if pid.strip()]
    if not target_pids:
        logger.warning("æœªé…ç½®æœ‰æ•ˆç›®æ ‡æ–‡ä»¶å¤¹IDï¼Œä¸æ‰§è¡Œæ¸…ç†æ“ä½œ")
        return

    if not client_115:
        init_115_client()
    client = client_115

    try:
        for cid in target_pids:
            logger.info(f"å¼€å§‹æ¸…ç†æ–‡ä»¶å¤¹ {cid} å†…çš„å†…å®¹...")
            offset = 0
            limit = 100
            while True:
                try:
                    resp = client.fs_files(cid=cid, limit=limit, offset=offset)
                    check_response(resp)
                    data = resp.get("data", [])
                    contents = data.get("list", []) if isinstance(data, dict) else data
                    if not contents:
                        logger.info(f"æ–‡ä»¶å¤¹ {cid} å†…æ— å†…å®¹ï¼Œæ¸…ç†å®Œæˆ")
                        break
                    for item in contents:
                        normalized_item = normalize_attr_simple(item)
                        item_id = normalized_item.get("id")
                        item_name = normalized_item.get("name", "æœªçŸ¥åç§°")
                        if not item_id: continue
                        try:
                            logger.info(f"åˆ é™¤: {item_name} (ID: {item_id})")
                            client.fs_delete(item_id)
                            time.sleep(0.5)
                        except Exception as e:
                            logger.error(f"åˆ é™¤ {item_name} å¤±è´¥: {str(e)}")
                    if len(contents) < limit:
                        logger.info(f"æ–‡ä»¶å¤¹ {cid} å†…å®¹å·²å…¨éƒ¨æ¸…ç†")
                        break
                    offset += limit
                except Exception as e:
                    logger.error(f"è·å–æ–‡ä»¶å¤¹ {cid} å†…å®¹å¤±è´¥: {str(e)}")
                    break

        logger.info("å¼€å§‹æ¸…ç©ºå›æ”¶ç«™...")
        try:
            client.fs_recyclebin_clean(password=TRASH_PASSWORD)
        except AttributeError:
            client.recyclebin_clean(password=TRASH_PASSWORD)
        logger.info("å›æ”¶ç«™æ¸…ç©ºå®Œæˆ")
    except Exception as e:
         logger.error(f"æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {e}")

def tg_115monitor():
    # å¼•ç”¨å…¨å±€å˜é‡
    global client_115, HDHIVE_INIT_DONE
    
    init_database()
    client = init_115_client()
    client_115 = client

    notifier = TelegramNotifier(TG_BOT_TOKEN, TG_ADMIN_USER_ID)
    logger.info(f"===== å¼€å§‹æ£€æŸ¥ 115ï¼ˆ{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼‰=====")
    
    # HDHive ä¿æ´»ä»»åŠ¡åˆå§‹åŒ– (ä»…æ‰§è¡Œä¸€æ¬¡)
    if not HDHIVE_INIT_DONE:
        try:
            if HDHIVE_USERNAME and HDHIVE_PASSWORD:
                logger.info("âš™ï¸ åˆå§‹åŒ– HDHive ä¿æ´»ä¸ç­¾åˆ°ä»»åŠ¡...")
                
                # ä»»åŠ¡1: æ¯30åˆ†é’Ÿä¿æ´» (é™é»˜æ‰§è¡Œï¼Œä»…é¦–æ¬¡æˆåŠŸé€šçŸ¥)
                schedule.every(30).minutes.do(hdhive_keep_alive, report=False)
                
                # ä»»åŠ¡2: æ¯å¤© 09:00 å¼ºåˆ¶æ‰§è¡Œå¹¶æ±‡æŠ¥ (æ— è®ºæˆåŠŸè¿˜æ˜¯å·²ç­¾åˆ°ï¼Œéƒ½å‘æ¶ˆæ¯)
                schedule.every().day.at("01:00").do(hdhive_keep_alive, report=True)
                
                # ç«‹å³æ‰§è¡Œä¸€æ¬¡ (å¯åŠ¨æ—¶é™é»˜æ£€æŸ¥)
                hdhive_keep_alive(report=False)
            else:
                logger.info("æœªé…ç½® HDHive è´¦å·ï¼Œè·³è¿‡ä¿æ´»åˆå§‹åŒ–")
        except Exception as e:
            logger.error(f"HDHive åˆå§‹åŒ–å¤±è´¥: {e}")
        finally:
            HDHIVE_INIT_DONE = True

    # æ‰§è¡Œå®šæ—¶ä»»åŠ¡ (HDHiveä¿æ´»)
    schedule.run_pending()
    
    new_messages = get_latest_messages()
    
    if new_messages:
        for msg in new_messages:
            message_id, date_str, message_url, target_url, message_text = msg
            logger.info(f"å¤„ç†æ–°æ¶ˆæ¯: {message_id} | {target_url}")

            # è°ƒç”¨è½¬å­˜ (TransferResult å¯¹è±¡)
            result = transfer_shared_link(client, target_url, UPLOAD_TRANSFER_PID)
            
            # ç›´æ¥ä½¿ç”¨ result.message è·å–è¯¦ç»†æ–‡æ¡ˆ
            if result:
                status = "å¤„ç†æˆåŠŸ"
                result_msg = f"{result.message}\næ¶ˆæ¯å†…å®¹: {message_url}\né“¾æ¥: {target_url}"
            else:
                status = "å¤„ç†å¤±è´¥"
                result_msg = f"{result.message}\næ¶ˆæ¯å†…å®¹: {message_url}\né“¾æ¥: {target_url}"

            notifier.send_message(result_msg)
            save_message(message_id, date_str, message_url, target_url, status, result_msg)
    else:
        logger.info("æœªå‘ç°æ–°çš„115åˆ†äº«é“¾æ¥")
        
    sync_cookies_to_files(client)

def sync_cookies_to_files(client):
    import re
    import os
    if not client: return
    try:
        raw_data = ""
        if hasattr(client.cookies, 'get_dict'):
            d = client.cookies.get_dict()
            raw_data = "; ".join([f"{k}={v}" for k, v in d.items()])
        elif isinstance(client.cookies, dict):
            raw_data = "; ".join([f"{k}={v}" for k, v in client.cookies.items()])
        else:
            raw_data = str(client.cookies)

        target_keys = ['UID', 'CID', 'SEID', 'KID', 'acw_tc']
        clean_pairs = []
        for key in target_keys:
            match = re.search(fr'(?:^|[\s;:]){key}=([^;\s]+)', raw_data, re.IGNORECASE)
            if match:
                value = match.group(1)
                if 'Set-Cookie' not in value:
                    clean_pairs.append(f"{key}={value}")

        if not clean_pairs: return
        new_cookies = "; ".join(clean_pairs)

        try:
            with open(COOKIES_FILE, 'w', encoding='utf-8') as f:
                f.write(new_cookies)
        except Exception as e:
            logger.error(f"å†™å…¥txtç¼“å­˜å¤±è´¥: {e}")
        
        env_path = "db/user.env"
        if os.path.exists(env_path):
            try:
                with open(env_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                new_lines = []
                key_found = False
                for line in lines:
                    if line.strip().startswith("ENV_115_COOKIES"):
                        new_lines.append(f"ENV_115_COOKIES='{new_cookies}'\n")
                        key_found = True
                    else:
                        new_lines.append(line)
                if not key_found:
                    new_lines.append(f"\nENV_115_COOKIES='{new_cookies}'\n")
                with open(env_path, 'w', encoding='utf-8') as f:
                    f.writelines(new_lines)
            except Exception as e:
                logger.error(f"å†™å…¥user.envå¤±è´¥: {e}")
    except Exception as e:
        logger.error(f"åŒæ­¥ Cookie å…¨å±€å¤±è´¥: {e}")

def main():
    # schedule.every().day.at("04:00").do(clean_task)
    try:       
        while True:
            tg_115monitor()
            time.sleep(CHECK_INTERVAL * 60)
    except KeyboardInterrupt:
        logger.info("ç¨‹åºå·²åœæ­¢")
    except Exception as e:
        logger.error(f"ç¨‹åºå¼‚å¸¸ç»ˆæ­¢: {str(e)}")

if __name__ == "__main__":
    
    main()
